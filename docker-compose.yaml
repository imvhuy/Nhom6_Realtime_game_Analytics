services:
  # =========================
  # Kafka Broker 1
  # =========================
  kafka1:
    image: apache/kafka:3.7.0
    container_name: kafka1
    hostname: kafka1
    ports:
      - "9092:9092"
      - "19092:19092" # cho Python host
    environment:
      # --- Node info ---
      KAFKA_NODE_ID: 1
      KAFKA_PROCESS_ROLES: broker,controller
      KAFKA_LISTENERS: INTERNAL://:9092,EXTERNAL://:19092,CONTROLLER://:29092
      KAFKA_ADVERTISED_LISTENERS: INTERNAL://kafka1:9092,EXTERNAL://localhost:19092
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: CONTROLLER:PLAINTEXT,INTERNAL:PLAINTEXT,EXTERNAL:PLAINTEXT
      KAFKA_CONTROLLER_LISTENER_NAMES: CONTROLLER
      KAFKA_CONTROLLER_QUORUM_VOTERS: 1@kafka1:29092,2@kafka2:29093
      KAFKA_INTER_BROKER_LISTENER_NAME: INTERNAL

      # --- Broker config ---
      KAFKA_LOG_DIRS: /var/lib/kafka/data
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 2
      KAFKA_TRANSACTION_STATE_LOG_REPLICATION_FACTOR: 2
      KAFKA_TRANSACTION_STATE_LOG_MIN_ISR: 1
      KAFKA_MIN_INSYNC_REPLICAS: 1
      KAFKA_GROUP_INITIAL_REBALANCE_DELAY_MS: 0

      # --- Cluster ID cố định ---
      KAFKA_CLUSTER_ID: my-cluster-id-1234

    volumes:
      - kafka1_data:/var/lib/kafka/data
    networks:
      - shared-network

  # =========================
  # Kafka Broker 2
  # =========================
  kafka2:
    image: apache/kafka:3.7.0
    container_name: kafka2
    hostname: kafka2
    ports:
      - "9093:9093"
      - "19093:19093" # cho Python host
    environment:
      KAFKA_NODE_ID: 2
      KAFKA_PROCESS_ROLES: broker,controller
      KAFKA_LISTENERS: INTERNAL://:9093,EXTERNAL://:19093,CONTROLLER://:29093
      KAFKA_ADVERTISED_LISTENERS: INTERNAL://kafka2:9093,EXTERNAL://localhost:19093
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: CONTROLLER:PLAINTEXT,INTERNAL:PLAINTEXT,EXTERNAL:PLAINTEXT
      KAFKA_CONTROLLER_LISTENER_NAMES: CONTROLLER
      KAFKA_CONTROLLER_QUORUM_VOTERS: 1@kafka1:29092,2@kafka2:29093
      KAFKA_INTER_BROKER_LISTENER_NAME: INTERNAL

      KAFKA_LOG_DIRS: /var/lib/kafka/data
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 2
      KAFKA_TRANSACTION_STATE_LOG_REPLICATION_FACTOR: 2
      KAFKA_TRANSACTION_STATE_LOG_MIN_ISR: 1
      KAFKA_MIN_INSYNC_REPLICAS: 1
      KAFKA_GROUP_INITIAL_REBALANCE_DELAY_MS: 0

      KAFKA_CLUSTER_ID: my-cluster-id-1234

    volumes:
      - kafka2_data:/var/lib/kafka/data
    networks:
      - shared-network
    depends_on:
      - kafka1

  # =========================
  # Kafka UI
  # =========================
  kafka-ui:
    image: provectuslabs/kafka-ui
    container_name: kafka-ui
    ports:
      - "8080:8080"
    environment:
      KAFKA_CLUSTERS_0_NAME: "game-cluster"
      KAFKA_CLUSTERS_0_BOOTSTRAPSERVERS: "kafka1:9092,kafka2:9093"
    depends_on:
      - kafka1
      - kafka2
    networks:
      - shared-network

  # ==========================================================
  # SPARK CLUSTER
  # ==========================================================
  spark-master-streaming:
    image: bitnamilegacy/spark:3.5.5
    container_name: spark-master-streaming
    user: root
    environment:
      - SPARK_MODE=master
      - SPARK_MASTER_HOST=spark-master-streaming
      - HOME=/opt/bitnami/spark
      - SPARK_HOME=/opt/bitnami/spark
      - SPARK_SUBMIT_OPTS=-Duser.home=/opt/bitnami/spark -Divy.home=/opt/bitnami/spark/.ivy2 -Divy.cache.dir=/opt/bitnami/spark/.ivy2/cache -Dsbt.ivy.home=/opt/bitnami/spark/.ivy2
      - SPARK_USER=spark
    ports:
      - "8081:8080"
      - "7077:7077"
    volumes:
      - spark_ivy_cache:/opt/bitnami/spark/.ivy2
      - ./code:/opt/spark-code
    command: >
      bash -c "
        mkdir -p /opt/bitnami/spark/.ivy2/cache &&
        mkdir -p /opt/bitnami/spark/.ivy2/local &&
        chmod -R 777 /opt/bitnami/spark/.ivy2 &&
        /opt/bitnami/scripts/spark/entrypoint.sh /opt/bitnami/scripts/spark/run.sh
      "
    networks:
      - shared-network
    depends_on:
      - kafka1
      - kafka2

  spark-worker-streaming:
    image: bitnamilegacy/spark:3.5.5
    container_name: spark-worker-streaming
    user: root
    environment:
      - SPARK_MODE=worker
      - SPARK_MASTER_URL=spark://spark-master-streaming:7077
      - SPARK_WORKER_MEMORY=2g
      - SPARK_WORKER_CORES=2
      - HOME=/opt/bitnami/spark
      - SPARK_HOME=/opt/bitnami/spark
      - SPARK_SUBMIT_OPTS=-Duser.home=/opt/bitnami/spark -Divy.home=/opt/bitnami/spark/.ivy2 -Divy.cache.dir=/opt/bitnami/spark/.ivy2/cache -Dsbt.ivy.home=/opt/bitnami/spark/.ivy2
      - SPARK_USER=spark
    ports:
      - "8082:8081"
    volumes:
      - spark_ivy_cache:/opt/bitnami/spark/.ivy2
      - ./code:/opt/spark-code
    command: >
      bash -c "
        mkdir -p /opt/bitnami/spark/.ivy2/cache &&
        mkdir -p /opt/bitnami/spark/.ivy2/local &&
        chmod -R 777 /opt/bitnami/spark/.ivy2 &&
        /opt/bitnami/scripts/spark/entrypoint.sh /opt/bitnami/scripts/spark/run.sh
      "
    depends_on:
      - spark-master-streaming
    networks:
      - shared-network

  # ==========================================================
  # MONGODB
  # ==========================================================
  mongodb:
    image: mongo:6
    container_name: mongodb
    ports:
      - "27017:27017"
    volumes:
      - mongo_data:/data/db
    networks:
      - shared-network

networks:
  shared-network:
    driver: bridge

volumes:
  mongo_data:
  kafka1_data:
  kafka2_data:
  spark_ivy_cache:
