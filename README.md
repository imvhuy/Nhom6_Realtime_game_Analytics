# ğŸ® Real-time Steam Game Analytics Platform

**NhÃ³m 6 - Big Data & Real-time Processing**

Há»‡ thá»‘ng phÃ¢n tÃ­ch dá»¯ liá»‡u game real-time tá»« Steam API sá»­ dá»¥ng Kafka, Spark Structured Streaming vÃ  MongoDB.

## ğŸ“‹ Table of Contents

- [Tá»•ng Quan](#-tá»•ng-quan)
- [Kiáº¿n TrÃºc Há»‡ Thá»‘ng](#-kiáº¿n-trÃºc-há»‡-thá»‘ng)
- [CÃ´ng Nghá»‡ Sá»­ Dá»¥ng](#-cÃ´ng-nghá»‡-sá»­-dá»¥ng)
- [YÃªu Cáº§u Há»‡ Thá»‘ng](#-yÃªu-cáº§u-há»‡-thá»‘ng)
- [CÃ i Äáº·t vÃ  Khá»Ÿi Äá»™ng](#-cÃ i-Ä‘áº·t-vÃ -khá»Ÿi-Ä‘á»™ng)
- [Sá»­ Dá»¥ng](#-sá»­-dá»¥ng)
- [Cáº¥u TrÃºc Dá»¯ Liá»‡u](#-cáº¥u-trÃºc-dá»¯-liá»‡u)
- [Monitoring & Visualization](#-monitoring--visualization)
- [Troubleshooting](#-troubleshooting)

---

## ğŸ¯ Tá»•ng Quan

Há»‡ thá»‘ng streaming real-time phÃ¢n tÃ­ch dá»¯ liá»‡u ngÆ°á»i chÆ¡i Steam, bao gá»“m:

- **Player Status Tracking**: Theo dÃµi tráº¡ng thÃ¡i online/offline cá»§a ngÆ°á»i chÆ¡i
- **Game Statistics**: PhÃ¢n tÃ­ch thá»‘ng kÃª game chi tiáº¿t (kills, deaths, win rate, KD ratio)
- **CCU Analytics**: TÃ­nh toÃ¡n Concurrent Users theo country vÃ  time windows
- **Real-time Dashboard**: Visualization vá»›i Grafana

### âœ¨ TÃ­nh NÄƒng ChÃ­nh

- âš¡ Real-time streaming vá»›i Kafka
- ğŸ”¥ Processing vá»›i Spark Structured Streaming
- ğŸ“Š Windowed aggregations (5-minute windows)
- ğŸŒ Geographic analytics (CCU by country)
- ğŸ“ˆ Player performance metrics (KD ratio, win rate)
- ğŸ¯ Upsert mechanism Ä‘á»ƒ trÃ¡nh duplicate
- ğŸ“‰ Time-series data vá»›i watermark support

---

## ğŸ—ï¸ Kiáº¿n TrÃºc Há»‡ Thá»‘ng

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Steam API     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Producer       â”‚â”€â”€â”€â”€â”€â–¶â”‚  Kafka Cluster   â”‚
â”‚  (Python)       â”‚      â”‚  (2 brokers)     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                  â”‚
                                  â–¼
                         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                         â”‚ Spark Streaming  â”‚
                         â”‚ (Master+Worker)  â”‚
                         â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                  â”‚
                                  â–¼
                         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                         â”‚    MongoDB       â”‚
                         â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                  â”‚
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â–¼                           â–¼
           â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
           â”‚    Grafana     â”‚         â”‚ Mongo Expressâ”‚
           â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Data Flow

1. **Producer** (`produce_v2.py`) gá»i Steam API â†’ Kafka
2. **Kafka** (2 brokers) lÆ°u messages vÃ o 2 topics:
   - `steam_players` - ThÃ´ng tin ngÆ°á»i chÆ¡i
   - `steam_userstats` - Thá»‘ng kÃª game
3. **Spark Streaming** (`spark_consumer.py`) xá»­ lÃ½ vÃ  aggregate
4. **MongoDB** lÆ°u 4 collections:
   - `player_details` - Chi tiáº¿t ngÆ°á»i chÆ¡i
   - `user_stats` - Thá»‘ng kÃª game
   - `ccu_windowed` - CCU theo country/time
   - `ccu_global` - CCU toÃ n há»‡ thá»‘ng
5. **Grafana** + **Mongo Express** Ä‘á»ƒ visualization

---

## ğŸ› ï¸ CÃ´ng Nghá»‡ Sá»­ Dá»¥ng

| Component | Technology | Version |
|-----------|-----------|---------|
| **Message Queue** | Apache Kafka | 3.7.0 |
| **Stream Processing** | Apache Spark | 3.5.5 |
| **Database** | MongoDB | 6.0 |
| **Visualization** | Grafana | 11.1.4 |
| **API Integration** | Python + aiohttp | 3.10 |
| **Container** | Docker + Docker Compose | Latest |

### Python Libraries

- `kafka-python` - Kafka producer
- `pyspark` - Spark Structured Streaming
- `pymongo` - MongoDB driver
- `aiohttp` - Async HTTP client
- `pandas`, `numpy` - Data processing

---

## ğŸ’» YÃªu Cáº§u Há»‡ Thá»‘ng

### Hardware
- **RAM**: Tá»‘i thiá»ƒu 8GB (khuyáº¿n nghá»‹ 16GB)
- **CPU**: 4 cores trá»Ÿ lÃªn
- **Disk**: 10GB trá»‘ng
- **Network**: Káº¿t ná»‘i internet á»•n Ä‘á»‹nh

### Software
- **OS**: Windows 10/11, Linux, macOS
- **Docker Desktop**: Version 20.10+
- **Docker Compose**: Version 2.0+
- **Python**: 3.10+ (cho producer)
- **Git**: Äá»ƒ clone repository

### Steam API Key
- ÄÄƒng kÃ½ táº¡i: https://steamcommunity.com/dev/apikey
- LÆ°u key vÃ o file `code/produce_v2.py`

---

## ğŸš€ CÃ i Äáº·t vÃ  Khá»Ÿi Äá»™ng

### BÆ°á»›c 1: Clone Repository

```bash
git clone https://github.com/imvhuy/Nhom6_Realtime_game_Analytics.git
cd Nhom6_Realtime_game_Analytics
```

### BÆ°á»›c 2: Cáº¥u HÃ¬nh Steam API Key

Má»Ÿ file `code/produce_v2.py` vÃ  thay tháº¿ API key:

```python
STEAM_API_KEY = "YOUR_STEAM_API_KEY_HERE"
```

### BÆ°á»›c 3: Build vÃ  Khá»Ÿi Äá»™ng Docker Containers

```bash
# Build custom Spark image vá»›i PyMongo
docker-compose build

# Khá»Ÿi Ä‘á»™ng táº¥t cáº£ services
docker-compose up -d

# Kiá»ƒm tra containers
docker ps
```

**Expected containers**:
- `kafka1` - Kafka broker 1
- `kafka2` - Kafka broker 2
- `kafka-ui` - Kafka web UI
- `spark-master-streaming` - Spark master
- `spark-worker-streaming` - Spark worker
- `mongodb` - MongoDB database
- `mongo-express` - MongoDB web UI
- `grafana` - Grafana dashboard
- `mongo-api` - REST API cho Grafana

### BÆ°á»›c 4: Táº¡o Kafka Topics (náº¿u chÆ°a cÃ³)

```bash
# Táº¡o topic cho player info
docker exec -it kafka1 /opt/kafka/bin/kafka-topics.sh \
  --create --topic steam_players \
  --bootstrap-server localhost:9092 \
  --partitions 3 --replication-factor 2

# Táº¡o topic cho user stats
docker exec -it kafka1 /opt/kafka/bin/kafka-topics.sh \
  --create --topic steam_userstats \
  --bootstrap-server localhost:9092 \
  --partitions 3 --replication-factor 2

# List topics
docker exec -it kafka1 /opt/kafka/bin/kafka-topics.sh \
  --list --bootstrap-server localhost:9092
```


### BÆ°á»›c 5: Cháº¡y Producer

```bash
# Tá»« thÆ° má»¥c code
python produce_v2.py
```

Báº¡n sáº½ tháº¥y:
```
ÄÃ£ náº¡p X steamid tá»« file steam_ids.csv
=== Báº®T Äáº¦U Láº¤Y Dá»® LIá»†U ===
ÄÃ£ gá»­i thÃ´ng tin ngÆ°á»i chÆ¡i ... vÃ o topic steam_players
ÄÃ£ gá»­i thá»‘ng kÃª game ... vÃ o topic steam_userstats
```

### BÆ°á»›c 6: Cháº¡y Spark Consumer



**Cháº¡y trÃªn docker**:
**Copy file spark_consumer.py vÃ o docker**:
```bash
docker cp code\spark_consumer.py spark-master-streaming:/opt/bitnami/spark/
```
```bash
docker exec -u 0 -it spark-master-streaming bash -c "export HOME=/root && spark-submit --packages org.apache.spark:spark-sql-kafka-0-10_2.12:3.5.5,org.mongodb.spark:mongo-spark-connector_2.12:10.2.0 --master local[*] /opt/bitnami/spark/spark_consumer.py" 
```

### BÆ°á»›c 8: Verify Data Flow

```bash
vÃ o mongo-express http://localhost:8083 Ä‘á»ƒ check data
```

---

## ğŸ“Š Sá»­ Dá»¥ng

### Web UIs

| Service | URL | Credentials |
|---------|-----|-------------|
| **Kafka UI** | http://localhost:8080 | None |
| **Spark Master** | http://localhost:8081 | None |
| **Spark Worker** | http://localhost:8082 | None |
| **MongoDB Express** | http://localhost:8083 | admin/admin |
| **Grafana** | http://localhost:3000 | admin/admin |
| **Mongo API** | http://localhost:5000 | None |

### Quick Commands

```bash
# Xem logs
docker logs kafka1 -f
docker logs spark-master-streaming -f
docker logs mongodb -f

# Restart services
docker-compose restart spark-master-streaming
docker-compose restart spark-worker-streaming

# Stop all
docker-compose down

# Clean volumes (âš ï¸ XÃ³a data)
docker-compose down -v
```

### Scripts Tiá»‡n Ãch

| Script | MÃ´ Táº£ |
|--------|-------|
| `run_spark_consumer.bat` | Cháº¡y Spark consumer |
| `restart_spark_clean.bat` | Restart vá»›i clean checkpoint |
| `clean_userstats.bat` | Clean user_stats collection |
| `verify_setup.bat` | Verify toÃ n bá»™ setup |
| `test_producer.bat` | Test producer |

---

## ğŸ—„ï¸ Cáº¥u TrÃºc Dá»¯ Liá»‡u

### 1. Collection: `player_details`

LÆ°u thÃ´ng tin vÃ  tráº¡ng thÃ¡i cá»§a tá»«ng ngÆ°á»i chÆ¡i.

```javascript
{
  "_id": ObjectId("..."),
  "steamid": "76561198012345678",
  "personaname": "PlayerName",
  "personastate": 1,
  "state_description": "Online",
  "country": "US",
  "state_code": "CA",
  "avatar": "https://...",
  "profileurl": "https://...",
  "timecreated": 1234567890,
  "last_seen": ISODate("2025-10-22T..."),
  "processed_time": ISODate("2025-10-22T..."),
  "_inserted_at": ISODate("2025-10-22T...")
}
```

**Indexes**:
```javascript
db.player_details.createIndex({"steamid": 1})
db.player_details.createIndex({"last_seen": -1})
db.player_details.createIndex({"country": 1})
```

### 2. Collection: `user_stats`

Thá»‘ng kÃª game chi tiáº¿t cá»§a ngÆ°á»i chÆ¡i.

```javascript
{
  "_id": ObjectId("..."),
  "steamid": "76561198012345678",
  "game_name": "ValveTestApp260",
  "stats": {
    "total_kills": 62101,
    "total_deaths": 49242,
    "total_wins": 24605,
    "total_mvps": 6805,
    "total_kills_awp": 15498,
    "total_kills_ak47": 13509,
    // ... 160+ more stats
  },
  "achievements": {
    "PLAY_CS2": 1
  },
  "total_kills": 62101,
  "total_deaths": 49242,
  "total_wins": 24605,
  "total_mvps": 6805,
  "total_matches_played": 2657,
  "total_matches_won": 949,
  "kd_ratio": 1.26,
  "win_rate": 35.72,
  "event_time": ISODate("2025-10-22T..."),
  "_updated_at": ISODate("2025-10-22T...")
}
```

**Indexes**:
```javascript
db.user_stats.createIndex({"steamid": 1}, {unique: true})
db.user_stats.createIndex({"kd_ratio": -1})
db.user_stats.createIndex({"win_rate": -1})
db.user_stats.createIndex({"total_kills": -1})
```

### 3. Collection: `ccu_windowed`

CCU (Concurrent Users) theo country vÃ  time windows.

```javascript
{
  "_id": ObjectId("..."),
  "window_start": ISODate("2025-10-22T15:00:00Z"),
  "window_end": ISODate("2025-10-22T15:05:00Z"),
  "country": "US",
  "unique_players": 150,
  "online_count": 120,
  "offline_count": 20,
  "away_count": 10,
  "avg_persona_state": 1.2,
  "computation_time": ISODate("2025-10-22T..."),
  "_updated_at": ISODate("2025-10-22T...")
}
```

**Indexes**:
```javascript
db.ccu_windowed.createIndex({"window_start": 1, "country": 1}, {unique: true})
db.ccu_windowed.createIndex({"window_start": -1})
```

### 4. Collection: `ccu_global`

CCU toÃ n há»‡ thá»‘ng theo time windows.

```javascript
{
  "_id": ObjectId("..."),
  "window_start": ISODate("2025-10-22T15:00:00Z"),
  "window_end": ISODate("2025-10-22T15:05:00Z"),
  "total_unique_players": 500,
  "total_online": 400,
  "total_offline": 80,
  "total_away": 20,
  "online_percentage": 80.0,
  "active_countries": 25,
  "computation_time": ISODate("2025-10-22T..."),
  "_updated_at": ISODate("2025-10-22T...")
}
```

**Indexes**:
```javascript
db.ccu_global.createIndex({"window_start": 1}, {unique: true})
db.ccu_global.createIndex({"window_start": -1})
```

---

## ğŸ“ˆ Monitoring & Visualization

### Grafana Setup

1. **Truy cáº­p Grafana**: http://localhost:3000
2. **Login**: admin/admin
3. **Add Data Source**:
   - Type: **Infinity** (JSON/CSV/GraphQL)
   - URL: `http://mongo-api:5000`

### Sample Queries

**MongoDB Queries** (xem file `MONGODB_QUERIES.md`):

```javascript
// Top KD Ratio
db.user_stats.find().sort({"kd_ratio": -1}).limit(10)

// CCU Trend (last 24 hours)
db.ccu_global.find({
  "window_start": {$gte: new Date(Date.now() - 24*60*60*1000)}
}).sort({"window_start": 1})

// CCU by Country
db.ccu_windowed.aggregate([
  {$group: {
    _id: "$country",
    avg_players: {$avg: "$unique_players"}
  }},
  {$sort: {"avg_players": -1}}
])
```

### Dashboard Panels

1. **Player Count Trend** - Line chart
2. **CCU by Country** - Bar chart
3. **Top Players by KD** - Table
4. **Win Rate Distribution** - Histogram
5. **Active Countries Map** - Geo map

---

## ğŸ”§ Troubleshooting

### Producer Issues

**Problem**: `Connection refused to Kafka`
```bash
# Check Kafka brokers
docker ps | grep kafka

# Verify ports
netstat -an | findstr "19092"
```

**Solution**: Ensure Kafka containers running vÃ  ports exposed.

---

### Spark Consumer Issues

**Problem**: `MongoDB connection error`
```bash
# Test connection from Spark container
docker exec -it spark-master-streaming ping mongodb

# Test MongoDB directly
docker exec -it mongodb mongosh --eval "db.version()"
```

**Solution**: 
- Ensure MongoDB container running
- Use `mongodb:27017` (service name), NOT `localhost:27017`

---

**Problem**: `Only player_details has data, others empty`

**Solution**: 
- Windowed queries need `outputMode("update")`, not `append`
- Check file `WINDOWED_FIX.md` for details

---

**Problem**: `User stats not parsing correctly`

**Solution**:
```bash
# Test parsing logic
cd code
python test_userstats_parsing.py

# Clean and restart
cd ..
clean_userstats.bat
```

---

### Docker Issues

**Problem**: `Out of memory`
```bash
# Increase Docker memory
# Docker Desktop â†’ Settings â†’ Resources â†’ Memory: 8GB+
```

---

**Problem**: `Port already in use`
```bash
# Find process using port
netstat -ano | findstr "8080"

# Kill process (Windows)
taskkill /F /PID <PID>

# Or change port in docker-compose.yaml
```

---

## ğŸ“š Documentation

- `FIX_GUIDE.md` - Fix MongoDB Connector issue
- `WINDOWED_FIX.md` - Fix windowed aggregation
- `DOCKER_NETWORK_FIX.md` - Docker networking guide
- `USERSTATS_GUIDE.md` - User stats implementation
- `MONGODB_QUERIES.md` - MongoDB query examples

---

## ğŸ‘¥ Team Members

- **NhÃ³m 6** - Big Data & Real-time Processing
- Repository: [Nhom6_Realtime_game_Analytics](https://github.com/imvhuy/Nhom6_Realtime_game_Analytics)

---

## ğŸ“ License

This project is for educational purposes.

---

## ğŸ™ Acknowledgments

- Steam API Documentation
- Apache Kafka & Spark Communities
- MongoDB Documentation
- Grafana Community

---

## ğŸ“ Support

Náº¿u gáº·p váº¥n Ä‘á», vui lÃ²ng:
1. Check `Troubleshooting` section
2. Review relevant `.md` files
3. Check Docker logs
4. Create issue on GitHub

**Happy Streaming! ğŸš€ğŸ®**

BÆ°á»›c 1:
dit me m thang thao ngu
buoc 2:
c